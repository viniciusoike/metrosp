# metrosp

R data package providing Sao Paulo Metro (METRO SP) passenger demand data (2017-2025).
Similar to nycflights13: datasets only, no user-facing functions.

## Package Structure

```
metrosp/
├── R/
│   └── data.R                     # Roxygen2 docs for all 9 exported datasets (NO functions)
├── data/                          # Lazy-loaded .rda datasets (the package deliverable)
│   ├── passengers_entrance.rda
│   ├── passengers_transported.rda
│   ├── station_averages.rda
│   ├── metro_lines.rda
│   ├── metro_lines_geo.rda
│   ├── metro_stations_geo.rda
│   ├── train_lines.rda
│   ├── train_lines_geo.rda
│   └── train_stations_geo.rda
├── data-raw/                      # ETL pipeline (excluded from built package via .Rbuildignore)
│   ├── run_pipeline.R             # Master orchestrator with download/historical/geosampa flags
│   ├── make_datasets.R            # Schema harmonization + .rda creation (287 lines)
│   ├── utils.R                    # Shared dimension tables and utility functions (310+ lines)
│   ├── download_metro.R           # Scrapes raw CSV/PDF/ZIP from METRO transparency portal
│   ├── import_passenger_2017_19.R      # Passenger entrance + transported ETL (2017-2019)
│   ├── import_daily_2017_19.R          # Station averages ETL (2017-2019)
│   ├── import_passengers_entrance.R    # Passenger entrance ETL (2020-2025)
│   ├── import_passengers_transported.R # Passenger transported ETL (2020-2025)
│   ├── import_station_averages.R       # Station averages ETL (2020-2025)
│   ├── import_station_daily.R          # INCOMPLETE: daily station data (not in v0.1.0)
│   ├── import_geosampa.R              # GeoSampa spatial data ETL (metro + CPTM train)
│   ├── clean_metro.R                  # ARCHIVE: 1,065 lines of scratch code, kept for reference
│   ├── processed/              # Intermediate CSVs (~600KB, committed to git)
│   ├── geosampa/               # GeoSampa GPKG source files (9 files)
│   └── metro_sp/               # Raw source files (gitignored, ~46MB)
├── man/                        # Auto-generated .Rd files (never edit manually)
├── tests/
│   ├── testthat.R              # Standard testthat setup
│   └── testthat/
│       ├── test-datasets.R     # 27 tests: schema, types, values, duplicates, data gaps
│       └── test-geo-datasets.R # 14 tests: sf objects, CRS, status values (skipped if sf absent)
├── DESCRIPTION                 # Package metadata (v0.1.0, MIT license, R >= 3.5.0)
├── NAMESPACE                   # Auto-generated by roxygen2 (empty — data-only package)
├── PLAN.md                     # Original development/restructuring plan
├── IMPROVEMENTS.md             # TODO list with raw data audit and future features
├── NEWS.md                     # Changelog
└── README.md                   # Installation, usage, data sources
```

## Exported Datasets

| Dataset | Rows | Description |
|---|---|---|
| `passengers_entrance` | 2,425 | Monthly passenger entries by metro line (2017-2025) |
| `passengers_transported` | 2,425 | Monthly passengers transported by metro line (2017-2025) |
| `station_averages` | 6,222 | Average weekday passenger entries by station (2017-2025) |
| `metro_lines` | 13 | Reference table: line number, Portuguese/English names |
| `metro_lines_geo` | sf | Metro line route geometries (LINESTRING, EPSG:4326, current + planned) |
| `metro_stations_geo` | sf | Metro station point locations (POINT, EPSG:4326, current + planned) |
| `train_lines` | 8 | CPTM train line reference table (lines 7-14) |
| `train_lines_geo` | sf | CPTM train line route geometries (LINESTRING, EPSG:4326) |
| `train_stations_geo` | sf | CPTM train station point locations (POINT, EPSG:4326) |

### Dataset Schemas

**passengers_entrance / passengers_transported**:
`date (Date), year (int), line_number (int), line_name_pt (char), line_name (char), metric (char), metric_abb (char), value (numeric)`

**station_averages**:
`date (Date), year (int), line_number (int), line_name_pt (char), line_name (char), station_name (char), avg_passenger (numeric)`

**metro_lines / train_lines**:
`line_number (int), line_name_pt (char), line_name (char)`

**Spatial datasets** (metro_lines_geo, metro_stations_geo, train_lines_geo, train_stations_geo):
`line_number (int), line_name_pt (char), line_name (char), company (char), status (char: "current"|"planned"), geometry (sfc)`
Station datasets also include `station_name (char)`.

## Key Rules

- This is a **data-only package**. `R/` contains ONLY `data.R` (documentation). **Never add functions to `R/`.**
- `NAMESPACE` is auto-generated by roxygen2. Never edit it manually.
- `man/` files are auto-generated by `devtools::document()`. Never edit them manually.
- `data-raw/metro_sp/` is gitignored (~46MB raw files). **Never commit it.**
- `data-raw/processed/` IS committed to git (intermediate CSVs, ~600KB).
- The 2017-2019 and 2020-2025 raw CSVs have **completely different column schemas**. All harmonization happens in `make_datasets.R`.
- All spatial data uses **EPSG:4326 (WGS84)** coordinate reference system.
- Metro lines are numbered 1-6 and 15-22 (with 99 = network total). CPTM train lines are 7-14.

## Data Sources

- Passenger demand data: https://transparencia.metrosp.com.br/dataset/demanda (Companhia do Metropolitano de Sao Paulo)
- Spatial data (lines/stations): https://geosampa.prefeitura.sp.gov.br/ (Prefeitura de Sao Paulo)

## Known Data Gaps

- **Line 5 (Lilas/Lilac)**: Available Oct 2017 - Dec 2019 only. Missing from all 2020-2025 raw data.
- **2017**: Only Oct-Dec available (CSV data starts October 2017; Jan-Sep is PDF only).
- **2025**: Trailing months may have NA values (data not yet published at time of download).
- **Network total (line 99)**: In 2017-2019 explicitly labeled; in 2020-2025 stored as NA line_number then mapped to 99.
- **Daily station data**: 6 raw CSVs exist (2020-2025) but `import_station_daily.R` is incomplete. Not included in v0.1.0.
- **Station metrics**: Only weekday average (mdu) available at station level. Line-level has all 5 metrics (total, mdu, msa, mdo, max).
- **Line 15 stations**: 10 stations in 2020, 11 from 2021 onward (Vila Prudente added).

## Development Workflow

### Full pipeline (from scratch)

1. Download raw data: `source("data-raw/download_metro.R")` → writes to `data-raw/metro_sp/` (~46MB)
2. Run import scripts to create intermediates in `data-raw/processed/`:
   - `source("data-raw/import_passenger_2017_19.R")` — 2017-2019 entrance + transported
   - `source("data-raw/import_daily_2017_19.R")` — 2017-2019 station averages
   - `source("data-raw/import_passengers_entrance.R")` — 2020-2025 entrance
   - `source("data-raw/import_passengers_transported.R")` — 2020-2025 transported
   - `source("data-raw/import_station_averages.R")` — 2020-2025 station averages
   - `source("data-raw/import_geosampa.R")` — spatial datasets from GPKG files
3. Build final .rda datasets: `source("data-raw/make_datasets.R")` → reads processed CSVs, harmonizes schemas, writes to `data/`
4. Generate documentation: `devtools::document()` → creates `man/` pages from `R/data.R`
5. Validate package: `devtools::check()`

Alternatively, use the orchestrator: `source("data-raw/run_pipeline.R")` with flags at the top of the file to control which steps run.

### Incremental updates (datasets already built)

- Edit ETL scripts in `data-raw/`, then run `source("data-raw/make_datasets.R")`
- After changing `R/data.R`, run `devtools::document()` to regenerate `man/` pages
- Run `devtools::check()` to validate

### Adding a new year of data

1. Run `source("data-raw/download_metro.R")` to fetch new files
2. The 2020-2025 import scripts iterate over years automatically — they should pick up new data
3. Run `source("data-raw/make_datasets.R")` to rebuild .rda files
4. Update date ranges in `R/data.R` documentation if needed
5. Run `devtools::document()` and `devtools::check()`

## ETL Architecture

### Pipeline flow

```
Raw CSVs (data-raw/metro_sp/)      GPKG files (data-raw/geosampa/)
         │                                    │
    import_*.R scripts                  import_geosampa.R
         │                                    │
    Intermediate CSVs                    Direct to .rda
  (data-raw/processed/)                  (data/)
         │
    make_datasets.R
    (harmonize + merge)
         │
    Final .rda files (data/)
```

### Schema harmonization (make_datasets.R)

The 2017-2019 and 2020-2025 data have different column names, metric formats, and structure. `make_datasets.R` handles:
- Mapping Portuguese metric names to English abbreviations (e.g., "Média dos Dias Úteis" → "mdu")
- Case-insensitive metric matching via `map_metric()` in utils.R
- Adding `line_name_pt` and `line_name` columns via joins to `metro_lines` reference table
- Renaming stations that changed names over time (Carrão, Penha, Saúde, Patriarca)
- Converting Portuguese number formats (dots as thousands separators) via `as_numeric_pt()`
- Mapping NA line numbers to 99 (network total) for 2020-2025 data
- 10+ sanity checks (date validity, line number ranges, date ranges)

### Key dimension tables (utils.R)

- `dim_line`: 13 metro lines with Portuguese/English names and line numbers (1-6, 15-22, 99)
- `dim_train_line`: 8 CPTM train lines (Ruby, Diamond, Emerald, Turquoise, Coral, Sapphire, Jade, Onyx)
- `dim_station_name_change`: Station rename mappings for historical consistency
- `dim_metric`: 5 metric types (total, mdu, msa, mdo, max) with Portuguese/English labels

### ETL script dependencies

Scripts used in `data-raw/` depend on packages NOT listed in DESCRIPTION Suggests (since data-raw/ is not shipped):
- readr, dplyr, tidyr, stringr, purrr, janitor, lubridate — data manipulation
- data.table — fast CSV parsing for 2017-2019 files
- rvest — web scraping for download script
- sf — spatial data for GeoSampa import
- usethis — `use_data()` to create .rda files
- here, cli, glue, import, stringi — utilities

## Testing

### Test structure

- **test-datasets.R** (27 assertions, 12 test blocks): Validates all non-spatial datasets
  - Datasets load as data.frames with expected columns
  - `metro_lines` has exactly 13 rows
  - No NA dates, row counts > 0
  - Line numbers match `metro_lines` reference
  - Date range starts at 2017-10-01
  - Column types correct (Date, numeric, character)
  - Values non-negative
  - No duplicate date/line/metric combinations
  - Station names have no trailing whitespace
  - Line 5 only appears in pre-2020 data

- **test-geo-datasets.R** (14 assertions): Validates spatial datasets
  - Skips all tests if `sf` package not installed
  - Datasets load as sf objects with expected columns
  - CRS is WGS84 (EPSG:4326)
  - Status column only contains "current" or "planned"
  - Metro has 6 current unique lines, CPTM has 7
  - No empty station names

### Running tests

```r
devtools::test()           # Run all tests
testthat::test_file("tests/testthat/test-datasets.R")     # Run specific file
testthat::test_file("tests/testthat/test-geo-datasets.R")  # Spatial tests (needs sf)
```

## Conventions

### Naming

- Dataset column names use **snake_case** in English
- Line names have both Portuguese (`line_name_pt`) and English (`line_name`) versions
- Metric abbreviations: `total`, `mdu` (weekday avg), `msa` (Saturday avg), `mdo` (Sunday avg), `max` (peak day)
- Spatial dataset status: `"current"` or `"planned"` (never other values)

### File naming in data-raw/

- `import_<subject>_<period>.R` for import scripts (e.g., `import_passenger_2017_19.R`)
- Processed CSVs: `metro_sp_<subject>_<period>.csv`
- Note: there is a known typo in `metro_sp_passengers_tranported_2020_2025.csv` ("tranported" instead of "transported") — do not rename without updating all references in `make_datasets.R`

### Code style

- ETL scripts use tidyverse conventions (dplyr pipes, tidyr pivots, purrr::safely)
- Portuguese number parsing handled by `as_numeric_pt()` in utils.R
- Encoding: most raw files are ISO-8859-1 (Latin-1); June 2018 files are UTF-8
- Scripts use `cli::cli_alert_*()` for progress messages and `cli::cli_abort()` for errors

### Package conventions

- `LazyData: true` — datasets auto-load when referenced (no `data()` call needed)
- `Config/testthat/edition: 3` — uses testthat 3rd edition
- `Roxygen: list(markdown = TRUE)` — roxygen2 supports markdown in documentation
- No vignettes yet (planned for future release)
- No CI/CD configured yet (GitHub Actions planned — see IMPROVEMENTS.md #11)

## Incomplete Work and Future Plans

See `IMPROVEMENTS.md` for the full TODO list. Key items:

- **Daily station data** (`import_station_daily.R`): Complex parallel-layout CSV parsing needed. Would add ~600K rows, possibly exceeding CRAN's 5MB limit.
- **GitHub Actions CI**: Not yet configured. Plan: `usethis::use_github_action("check-standard")`
- **Archive clean_metro.R**: 1,065 lines of scratch code. Could be moved to `data-raw/archive/` or deleted.
- **Generalize skip offsets**: Import scripts use hardcoded `case_when()` with magic numbers for CSV parsing offsets. Could be externalized to a config file.

## Quick Reference

| Task | Command |
|---|---|
| Rebuild datasets | `source("data-raw/make_datasets.R")` |
| Run full pipeline | `source("data-raw/run_pipeline.R")` |
| Generate docs | `devtools::document()` |
| Run tests | `devtools::test()` |
| Full check | `devtools::check()` |
| Download raw data | `source("data-raw/download_metro.R")` |
